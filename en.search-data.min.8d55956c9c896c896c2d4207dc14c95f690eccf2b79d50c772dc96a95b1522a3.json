[{"id":0,"href":"/reinforcement-learning/secondpost/","title":"두번째 글입니다. 블로그 실험용 테스트 글입니다.","section":"Reinforcement Learning / 강화학습","content":"\rtest\r#\rtest2\r#\rRL 관련 항목을 기록하기 위한 post 입니다.\n페이지 업로드 확인용 임시 포스트\n"},{"id":1,"href":"/aboutme/","title":"About Me","section":"Home","content":"Profile\nName : Jaeyoung Sim\n"},{"id":2,"href":"/reinforcement-learning/rl-essential/","title":"Reinforcement Learning Essential","section":"Reinforcement Learning / 강화학습","content":"\r강화학습에 대한 기초 내용\r#\r강화학습(RL: Reinforcement Learning) 이란?\r#\r“Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a numerical reward signal.”\n— Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction (2nd ed), p.1\rsituations을 state로 표기하여\n통상적으로 action, state와 reward 가 RL의 핵심 요소이다.\n요약하면, 주어진 상태(State)에서 보상(Reward)을 최대화 할 수 있는 행동(Action)을 학습하는 것\n이는 Reward Hypothesis를 기반으로한다. Reward Hypothesis All goals can be described by the maximisation of expected cumulative reward\r머신러닝(ML)과 딥러닝(DL)과의 차이점이 뭐지?\r#\r머신러닝(Machine Learning)은 인공지능(AI)의 개념으로써, 학습을 통해 예측(또는 분류)를 하는 것\n딥러닝은 머신러닝의 하위 개념으로써, 인공신경망(Neural Network)를 이용해서 학습하는 것\n강화 학습은 머신러닝의 한갈래로써, 보상을 기반으로 스스로 행동 학습하는 것\nAI\r├── Machine Learning\r│ ├── Supervised / Unsupervised\r│ ├── Reinforcement Learning\r│ └── Deep Learning\r│ └── Deep Reinforcement Learning (e.g., DQN, PPO) def hello(): print(\u0026#34;hi\u0026#34;) Pros \u0026amp; Cons\r#\rRL 학습을 위해서 추가적으로 공부해야할 개념\r#\rMP, MDP\n참고\r#\rDavid Silver 의 RL 강좌 https://davidstarsilver.wordpress.com/teaching\n"},{"id":3,"href":"/development/firstpost/","title":"첫번째 글입니다.","section":"Development / 개발","content":"개발 관련 항목을 기록하기 위한 post 입니다.\nTodo List:\n상태 날짜 작업 내용 ✅ 2025-05-21 블로그 GitHub Page 연동 ☐ RL 관련 Post 남기기 ☐ 블로그 setup 관련 post 남기기 hugo + github page + giscus ☐ About Me 완성 ☐ Google 서치 연동 "}]