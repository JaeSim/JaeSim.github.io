<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Markov on JaeSim&#39;s Workspace</title>
    <link>https://JaeSim.github.io/tags/markov/</link>
    <description>Recent content in Markov on JaeSim&#39;s Workspace</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Tue, 27 May 2025 16:43:57 +0900</lastBuildDate>
    <atom:link href="https://JaeSim.github.io/tags/markov/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2. Markov Decision Process</title>
      <link>https://JaeSim.github.io/reinforcement-learning/rl-mdp/</link>
      <pubDate>Tue, 27 May 2025 16:43:57 +0900</pubDate>
      <guid>https://JaeSim.github.io/reinforcement-learning/rl-mdp/</guid>
      <description>&lt;h1 id=&#34;2-markov-decision-process&#34;&gt;&#xD;&#xA;  &lt;strong&gt;2. Markov Decision Process&lt;/strong&gt;&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#2-markov-decision-process&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h1&gt;&#xD;&#xA;&lt;h2 id=&#34;markov-processmp-란&#34;&gt;&#xD;&#xA;  &lt;strong&gt;Markov Process(MP) 란?&lt;/strong&gt;&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#markov-processmp-%eb%9e%80&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&#xD;&#xA;&lt;h3 id=&#34;mp-속성&#34;&gt;&#xD;&#xA;  &lt;strong&gt;MP 속성&lt;/strong&gt;&#xD;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mp-%ec%86%8d%ec%84%b1&#34;&gt;#&lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&#xD;&#xA;&lt;p&gt;MDP는 환경에 대해서 Reinforcement Learning이 이해가능하도록 수식화한다&lt;/p&gt;&#xA;&lt;p&gt;거의 모든 RL 관련 문제들은 MDP로 수식화 할 수 있다(Fully observable이나 Partially ovservable이나)&lt;/p&gt;&#xA;&lt;p&gt;Markov Property를 이용하는데, &amp;ndash;이전 강의참조&amp;ndash;&lt;/p&gt;&#xA;&lt;p&gt;요약하면, 현재 state만으로 미래를 예측해도 된다는 속성이다.&#xA;(다르게 말하면, 현재 state가 이미 유용한 정보를 포함하고 있다. memoryless)&lt;/p&gt;&#xA;&lt;p&gt;Markov state &#xD;&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;https://JaeSim.github.io/katex/katex.min.css&#34; /&gt;&#xD;&#xA;&lt;script defer src=&#34;https://JaeSim.github.io/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;script defer src=&#34;https://JaeSim.github.io/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xD;&#xA;  \(s\)&#xD;&#xA;&lt;/span&gt;&#xD;&#xA;로부터 &lt;span&gt;&#xD;&#xA;  \(s&#39;\)&#xD;&#xA;&lt;/span&gt;&#xD;&#xA; 으로 변경하는 transition probability 를 하는 수식은 다음과 같다.&#xA;&lt;span&gt;&#xD;&#xA;  \[&#xD;&#xA;\mathcal{P}_{ss&#39;}  = \mathbb{P}[S_{t+1} = s&#39;\mid S_t = s]&#xD;&#xA;\]&#xD;&#xA;&lt;/span&gt;&#xD;&#xA;&#xA;매트릭스로 표현하면 다음과 같다. (합은 1)&#xA;&lt;span&gt;&#xD;&#xA;  \[&#xD;&#xA;\mathcal{P} =  \left[&#xD;&#xA;\begin{array}{ccc}&#xD;&#xA;\mathcal{P}_{11} &amp; \cdots &amp; \mathcal{P}_{1n} \\&#xD;&#xA;\vdots &amp; \ddots &amp; \vdots \\&#xD;&#xA;\mathcal{P}_{n1} &amp; \cdots &amp; \mathcal{P}_{nn}&#xD;&#xA;\end{array}&#xD;&#xA;\right]&#xD;&#xA;\]&#xD;&#xA;&lt;/span&gt;&#xD;&#xA;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
